{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from train_test import train, evaluate\n",
    "import warnings\n",
    "import json\n",
    "import wandb\n",
    "from arg_parser import init_parser\n",
    "from setproctitle import setproctitle as ptitle\n",
    "from enviroment import ARC_Env\n",
    "import gymnasium as gym\n",
    "from action_space import ARCActionSpace\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "def init_parser(alg):\n",
    "    \"\"\"Initialize argument parser for the specified algorithm.\"\"\"\n",
    "\n",
    "    if alg == 'WOLP_DDPG':\n",
    "        parser = argparse.ArgumentParser(description='WOLP_DDPG')\n",
    "\n",
    "        # Environment & Training Mode\n",
    "        parser.add_argument('--env', default='ARC', metavar='ENV', help='Environment to train on')\n",
    "        parser.add_argument('--mode', default='train', type=str, help='Mode: train/test')\n",
    "        parser.add_argument('--id', default='0', type=str, help='Experiment ID')\n",
    "        parser.add_argument('--load', default=True, metavar='L', help='Load a trained model')\n",
    "        parser.add_argument('--load-model-dir', default='ARC-run67', metavar='LMD', help='Folder to load trained models from')\n",
    "        parser.add_argument('--eval-interval', default=200, type=int, help='Evaluate model every X episodes')\n",
    "        parser.add_argument('--eval-episodes', default=2, type=int, help='Number of episodes to evaluate')\n",
    "\n",
    "        # Episode & Training Settings\n",
    "        parser.add_argument('--max-episode-length', type=int, default=50, metavar='M', help='Max episode length (default: 50)')  # Changed from 1440\n",
    "        parser.add_argument('--max-episode', type=int, default=20000, help='Maximum number of episodes')\n",
    "        parser.add_argument('--max-actions', default=12, type=int, help='# max actions')\n",
    "        parser.add_argument('--test-episode', type=int, default=20, help='Maximum testing episodes')\n",
    "        parser.add_argument('--warmup', default=200, type=int, help='Time without training but only filling the replay memory')\n",
    "        parser.add_argument('--bsize', default=3, type=int, help='Minibatch size')\n",
    "        parser.add_argument('--rmsize', default=100000, type=int, help='Replay memory size')\n",
    "\n",
    "        # Policy Update Settings\n",
    "        parser.add_argument('--gamma', type=float, default=0.99, metavar='G', help='Discount factor for rewards (default: 0.99)')\n",
    "        parser.add_argument('--policy-noise', default=0, type=float, help='Noise added to target policy during critic update')\n",
    "        parser.add_argument('--noise-clip', default=0.25, type=float, help='Range to clip target policy noise')\n",
    "        parser.add_argument('--policy-delay', default=2, type=int, help='Delay policy updates')\n",
    "        parser.add_argument('--c-lr', default=3e-4, type=float, help='Critic network learning rate')\n",
    "        parser.add_argument('--p-lr', default=3e-4, type=float, help='Policy network learning rate (for DDPG)')\n",
    "        parser.add_argument('--tau-update', default=0.0005, type=float, help='Moving average for target network')\n",
    "        parser.add_argument('--weight-decay', default=1e-4, type=float, help='L2 Regularization loss weight decay')\n",
    "        \n",
    "                            \n",
    "        # Neural Network Architecture\n",
    "        parser.add_argument('--hidden1', default=512, type=int, help='Hidden units in the first fully connected layer')\n",
    "        parser.add_argument('--hidden2', default=512, type=int, help='Hidden units in the second fully connected layer')\n",
    "        parser.add_argument('--actor_critic_type', default='cnn', type=str, help='Type of model (lpn, cnn, mlp)')\n",
    "        parser.add_argument('--latent_dim', default=48, type=int, help='Latent dimension for encoder')\n",
    "\n",
    "        # Exploration & Noise\n",
    "        parser.add_argument('--epsilon', default=100000, type=int, help='Linear decay of exploration policy')\n",
    "        parser.add_argument('--epsilon_start', default=1.0, type=float, help='Starting epsilon value for resuming training')\n",
    "        parser.add_argument('--ou_theta', default=0.5, type=float, help='Ornstein-Uhlenbeck noise theta')\n",
    "        parser.add_argument('--ou_sigma', default=0.2, type=float, help='Ornstein-Uhlenbeck noise sigma')\n",
    "        parser.add_argument('--ou_mu', default=0.0, type=float, help='Ornstein-Uhlenbeck noise mu')\n",
    "\n",
    "        # Hardware & GPU Settings\n",
    "        parser.add_argument('--gpu-ids', type=int, default=[1], nargs='+', help='GPUs to use [-1 for CPU only]')\n",
    "        parser.add_argument('--gpu-nums', type=int, default=8, help='Number of GPUs to use (default: 1)')\n",
    "\n",
    "        # Action Embedding & Filtering\n",
    "        parser.add_argument('--load_action_embedding', default=True, type=bool, help='Load action embedding or not')\n",
    "        parser.add_argument('--num_experiments_filter', default=120, type=int, help='Number of problems used for filtering actions')\n",
    "        parser.add_argument('--filter_threshold', default=0.3, type=float, help='Threshold percentage for filtering actions')\n",
    "        parser.add_argument('--num_experiments_similarity', default=120, type=int, help='Number of problems used for similarity matrix calculation')\n",
    "        parser.add_argument('--max_embedding', default=1., type=float, help='Maximum value for embedding matrix')\n",
    "        parser.add_argument('--min_embedding', default=-1., type=float, help='Minimum value for embedding matrix')\n",
    "\n",
    "        # Miscellaneous\n",
    "        parser.add_argument('--init_w', default=0.003, type=float, help='Initial weight')\n",
    "        parser.add_argument('--seed', default=-1, type=int, help='Random seed')\n",
    "        parser.add_argument('--save_per_epochs', default=25, type=int, help='Save model every X epochs')\n",
    "        parser.add_argument('--k_neighbors', default=25, type=int, help='Number of neighbors to consider')\n",
    "        return parser\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(f'Undefined algorithm {alg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.argv = ['notebook']  # Replace with a dummy argument list\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print('Using device: {}'.format(device))\n",
    "\n",
    "\n",
    "ptitle('WOLP_DDPG')\n",
    "warnings.filterwarnings('ignore')\n",
    "parser = init_parser('WOLP_DDPG')\n",
    "args = parser.parse_args()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_ids)[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to verify login in offline mode.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for model: mps\n",
      "Using device for EncoderTransformer: mps\n",
      "Using device for memory: mps\n",
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/francescobraicovich/Documents/ARC2 with outputs/ARC2/wandb/run-20250221_143820-cf2t9kzt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1/runs/cf2t9kzt' target=\"_blank\">soft-lion-95</a></strong> to <a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1' target=\"_blank\">https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1/runs/cf2t9kzt' target=\"_blank\">https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1/runs/cf2t9kzt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Creating the action space\n",
      "Number of actions not filtered: 11310\n",
      "Number of actions filtered: 7075\n",
      "NearestNeighbors model created with 25 neighbors\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Creating the action space\n",
      "Number of actions not filtered: 11310\n",
      "Number of actions filtered: 7075\n",
      "NearestNeighbors model created with 25 neighbors\n",
      "--------------------------------------------------\n",
      "[[-0.05092603  0.62167759 -0.80313564 -0.31519486 -0.05130663 -0.35953908\n",
      "  -0.48975622 -0.55581076 -0.57480736 -0.34074036 -0.29114123  0.90078503\n",
      "   0.0063453  -0.4454143  -0.17825451 -0.05588313  0.64388515  0.86552641\n",
      "  -0.08955657  0.7753709 ]\n",
      " [-0.04885672  0.80032061  0.66708647 -0.73917153 -0.10302403  0.59080581\n",
      "   0.62320497  0.07621358 -0.72033781  0.3629343  -0.02611465  0.07564433\n",
      "  -0.53731184 -0.20741292  0.47814419 -0.88411586  0.43059644  0.67943963\n",
      "  -0.06200402 -0.48741514]\n",
      " [-0.40096055  0.24775392  0.69482523  0.75425448 -0.65625216  0.04741802\n",
      "  -0.00910887 -0.01187057  0.6116402   0.68676669  0.54557457 -0.06771539\n",
      "   0.2488829  -0.24646899 -0.08990387 -0.90780779 -0.70003807 -0.02418659\n",
      "  -0.58351821  0.79935908]\n",
      " [ 0.38637632 -0.48902757  0.35099516  0.88802481  0.5586184  -0.2702459\n",
      "   0.52645431  0.69598575 -0.83457721 -0.16256426 -0.03058141 -0.85370094\n",
      "  -0.62142908 -0.65584228 -0.27616342 -0.28745875  0.38399772  0.03179606\n",
      "  -0.3963127  -0.3897269 ]\n",
      " [-0.25548909 -0.04250944 -0.63779067  0.43110926  0.01354426  0.41525981\n",
      "   0.78275776 -0.43854834 -0.3378158   0.22975273 -0.66367269 -0.65398663\n",
      "  -0.23389283  0.31030033  0.73377394  0.80006153  0.42101434 -0.24609203\n",
      "   0.73764714 -0.79499183]\n",
      " [ 0.63784856 -0.45535006 -0.20508811 -0.52576081 -0.066436   -0.62763359\n",
      "  -0.17060312  0.63826353 -0.5522275   0.17912172  0.55201242  0.47660991\n",
      "  -0.00966091 -0.85784553 -0.52982982 -0.74105383 -0.12160335  0.46696559\n",
      "  -0.14690418 -0.8235438 ]\n",
      " [-0.49338493  0.68566274 -0.56388726  0.40896429 -0.48764451  0.26394063\n",
      "  -0.78936402  0.82523075 -0.32484156 -0.5406515   0.27797599 -0.43001904\n",
      "  -0.18325645 -0.42723789  0.54450313 -0.52744692  0.64642437  0.68221378\n",
      "   0.46616133  0.25793232]\n",
      " [-0.52512656 -0.33106947 -0.47179517  0.53252761  0.4495257  -0.67423344\n",
      "  -0.21561418 -0.54235568  0.18978661 -0.62153701 -0.76319763 -0.53044154\n",
      "   0.76182336 -0.41486711  0.70524268  0.29975176  0.27175077  0.68428338\n",
      "   0.48464723  0.65513417]\n",
      " [ 0.76604864  0.78536572 -0.69208667  0.02209129 -0.45441202 -0.33889843\n",
      "  -0.77947541 -0.66173572 -0.17887929  0.18417119 -0.36650895  0.58738758\n",
      "  -0.72983942  0.15195974  0.59661623 -0.65919578  0.15597044 -0.42193826\n",
      "   0.42998319  0.60029417]\n",
      " [ 0.65394507 -0.30925665 -0.39426571  0.73018518 -0.24907473  0.01462021\n",
      "  -0.05669463  0.64568592 -0.23348351 -0.39301236  0.18676806  0.79184714\n",
      "   0.50573257  0.55121097 -0.76954497  0.51469792  0.77587309  0.54704368\n",
      "  -0.51624787  0.50546305]]\n",
      "Sample actions:  None\n",
      "Using device: mps for ddpg\n",
      "--------------------------------------------------\n",
      "At initialization:\n",
      "Difference between actor and actor_target:  0.0\n",
      "Difference between critic1 and critic1_target:  0.0\n",
      "Difference between critic2 and critic2_target:  0.0\n",
      "Difference between critic1 and critic2:  107.12167358398438\n",
      "Difference between critic1_target and critic2_target:  107.12167358398438\n",
      "--------------------------------------------------\n",
      "[WolpertingerAgent] Using device: mps\n",
      "[WolpertingerAgent] Using 25 nearest neighbors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 14:38:22,775 : env: ARC\n",
      "2025-02-21 14:38:22,776 : mode: train\n",
      "2025-02-21 14:38:22,776 : id: 0\n",
      "2025-02-21 14:38:22,776 : load: True\n",
      "2025-02-21 14:38:22,777 : load_model_dir: ARC-run67\n",
      "2025-02-21 14:38:22,777 : eval_interval: 200\n",
      "2025-02-21 14:38:22,777 : eval_episodes: 2\n",
      "2025-02-21 14:38:22,777 : max_episode_length: 50\n",
      "2025-02-21 14:38:22,778 : max_episode: 20000\n",
      "2025-02-21 14:38:22,778 : max_actions: 12\n",
      "2025-02-21 14:38:22,778 : test_episode: 20\n",
      "2025-02-21 14:38:22,779 : warmup: 200\n",
      "2025-02-21 14:38:22,779 : bsize: 3\n",
      "2025-02-21 14:38:22,779 : rmsize: 100000\n",
      "2025-02-21 14:38:22,779 : gamma: 0.99\n",
      "2025-02-21 14:38:22,780 : policy_noise: 0\n",
      "2025-02-21 14:38:22,780 : noise_clip: 0.25\n",
      "2025-02-21 14:38:22,780 : policy_delay: 2\n",
      "2025-02-21 14:38:22,780 : c_lr: 0.0003\n",
      "2025-02-21 14:38:22,781 : p_lr: 0.0003\n",
      "2025-02-21 14:38:22,781 : tau_update: 0.0005\n",
      "2025-02-21 14:38:22,781 : weight_decay: 0.0001\n",
      "2025-02-21 14:38:22,781 : hidden1: 512\n",
      "2025-02-21 14:38:22,782 : hidden2: 512\n",
      "2025-02-21 14:38:22,782 : actor_critic_type: cnn\n",
      "2025-02-21 14:38:22,782 : latent_dim: 48\n",
      "2025-02-21 14:38:22,782 : epsilon: 100000\n",
      "2025-02-21 14:38:22,782 : epsilon_start: 1.0\n",
      "2025-02-21 14:38:22,783 : ou_theta: 0.5\n",
      "2025-02-21 14:38:22,783 : ou_sigma: 0.2\n",
      "2025-02-21 14:38:22,783 : ou_mu: 0.0\n",
      "2025-02-21 14:38:22,783 : gpu_ids: [1]\n",
      "2025-02-21 14:38:22,783 : gpu_nums: 8\n",
      "2025-02-21 14:38:22,784 : load_action_embedding: True\n",
      "2025-02-21 14:38:22,784 : num_experiments_filter: 120\n",
      "2025-02-21 14:38:22,784 : filter_threshold: 0.3\n",
      "2025-02-21 14:38:22,784 : num_experiments_similarity: 120\n",
      "2025-02-21 14:38:22,785 : max_embedding: 1.0\n",
      "2025-02-21 14:38:22,785 : min_embedding: -1.0\n",
      "2025-02-21 14:38:22,785 : init_w: 0.003\n",
      "2025-02-21 14:38:22,785 : seed: -1\n",
      "2025-02-21 14:38:22,785 : save_per_epochs: 25\n",
      "2025-02-21 14:38:22,786 : k_neighbors: 25\n",
      "2025-02-21 14:38:22,786 : save_model_dir: ../output/ARC-run77\n",
      "2025-02-21 14:38:22,786 : nb_states: 1805\n",
      "2025-02-21 14:38:22,786 : nb_actions: 20\n",
      "2025-02-21 14:38:22,786 : continuous: False\n",
      "2025-02-21 14:38:22,787 : Starting Training...\n",
      "2025-02-21 14:38:22,894 : [Train] Ep:0    | R: -33.00 | Steps:   12 | EqualStates:    4 | PosR:    0 | eps: 1.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actor and Critic models loaded from ARC-run67\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train/episode</td><td>▁</td></tr><tr><td>train/episode_reward</td><td>▁</td></tr><tr><td>train/episode_steps</td><td>▁</td></tr><tr><td>train/epsilon</td><td>▁</td></tr><tr><td>train/positive_rewards</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train/episode</td><td>0</td></tr><tr><td>train/episode_reward</td><td>-33</td></tr><tr><td>train/episode_steps</td><td>12</td></tr><tr><td>train/epsilon</td><td>1</td></tr><tr><td>train/positive_rewards</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">soft-lion-95</strong> at: <a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1/runs/cf2t9kzt' target=\"_blank\">https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1/runs/cf2t9kzt</a><br> View project at: <a href='https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1' target=\"_blank\">https://wandb.ai/francesco-braicovich-bocconi-university/arc-v1</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250221_143820-cf2t9kzt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.util import get_output_folder, setup_logger\n",
    "from utils.util import set_device\n",
    "from wolp_agent import WolpertingerAgent\n",
    "import os\n",
    "\n",
    "# Change the current working directory to the parent folder\n",
    "os.chdir('..')\n",
    "\n",
    "# 2. Set CUDA visible devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_ids)[1:-1]\n",
    "device = set_device()\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# 3. Optionally set a process title\n",
    "ptitle('WOLP_DDPG')\n",
    "\n",
    "# 4. Prepare output folder\n",
    "args.save_model_dir = get_output_folder('../output', args.env)\n",
    "\n",
    "# 5. Initialize wandb (only if training)\n",
    "if args.mode == 'train' and wandb.run is None:\n",
    "    wandb.init(project=\"arc-v1\", config=vars(args), mode=\"online\")\n",
    "\n",
    "action_space = ARCActionSpace(args)\n",
    "action_space = ARCActionSpace(args)\n",
    "print('Sample actions: ', print(action_space))\n",
    "\n",
    "# 6. Create training and evaluation environments\n",
    "train_env = ARC_Env(\n",
    "    path_to_challenges='data/RAW_DATA_DIR/arc-prize-2024/arc-agi_training_challenges.json',\n",
    "    action_space=action_space\n",
    ")\n",
    "eval_env = ARC_Env(\n",
    "    path_to_challenges='data/RAW_DATA_DIR/arc-prize-2024/arc-agi_evaluation_challenges.json',\n",
    "    action_space=action_space\n",
    ")\n",
    "\n",
    "# 7. Set seeds\n",
    "if args.seed > 0:\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    train_env.seed(args.seed)\n",
    "    eval_env.seed(args.seed)\n",
    "\n",
    "# 8. Define state and action dimensions\n",
    "nb_states = 1805\n",
    "nb_actions = 20\n",
    "continuous = False\n",
    "\n",
    "# 9. Create the agent\n",
    "agent_args = {\n",
    "    'nb_states': nb_states,\n",
    "    'nb_actions': nb_actions,\n",
    "    'args': args,\n",
    "    'k': args.k_neighbors,\n",
    "    'action_space': action_space\n",
    "}\n",
    "agent = WolpertingerAgent(**agent_args)\n",
    "\n",
    "# 10. Optionally load model weights\n",
    "if args.load:\n",
    "    agent.load_weights(args.load_model_dir)\n",
    "\n",
    "# 11. Move agent to GPU if requested\n",
    "if args.gpu_ids[0] >= 0 and args.gpu_nums > 0 and torch.cuda.is_available():\n",
    "    agent.cuda_convert()\n",
    "\n",
    "# 12. Set up logger\n",
    "if args.mode == 'train':\n",
    "    setup_logger('RS_log', f'{args.save_model_dir}/RS_train_log')\n",
    "elif args.mode == 'test':\n",
    "    setup_logger('RS_log', f'{args.save_model_dir}/RS_test_log')\n",
    "else:\n",
    "    raise RuntimeError(f'Undefined mode {args.mode}')\n",
    "logger = logging.getLogger('RS_log')\n",
    "\n",
    "# 13. Log hyperparameters\n",
    "d_args = vars(args)\n",
    "d_args['nb_states'] = nb_states\n",
    "d_args['nb_actions'] = nb_actions\n",
    "d_args['continuous'] = continuous\n",
    "for k, v in d_args.items():\n",
    "    logger.info(f\"{k}: {v}\")\n",
    "\n",
    "# 14. Run training or (separate) test\n",
    "if args.mode == 'train':\n",
    "    logger.info('Starting Training...')\n",
    "    train(\n",
    "        continuous=continuous,\n",
    "        train_env=train_env,\n",
    "        eval_env=eval_env,\n",
    "        agent=agent,\n",
    "        max_episode=args.max_episode,\n",
    "        max_actions=args.max_actions,\n",
    "        warmup=args.warmup,\n",
    "        save_model_dir=args.save_model_dir,\n",
    "        max_episode_length=args.max_episode_length,\n",
    "        logger=logger,\n",
    "        save_per_epochs=args.save_per_epochs,\n",
    "        eval_interval=args.eval_interval,     # e.g. evaluate every 10 episodes\n",
    "        eval_episodes=args.eval_episodes     # e.g. 5 episodes each evaluation\n",
    "    )\n",
    "    # finish wandb run\n",
    "    wandb.finish()\n",
    "\n",
    "elif args.mode == 'test':\n",
    "    logger.info('Starting Testing...')\n",
    "    # You could reuse the 'evaluate' or a separate 'test(...)' function\n",
    "    from train_test import evaluate\n",
    "    evaluate(\n",
    "        agent=agent,\n",
    "        eval_env=eval_env,\n",
    "        episodes=args.test_episode,\n",
    "        max_episode_length=args.max_episode_length,\n",
    "        logger=logger\n",
    "    )\n",
    "else:\n",
    "    raise RuntimeError(f'Undefined mode {args.mode}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
